
% Script for Nearest Neighbors model
% CCTA data analysis
% Created 07-Apr-2018 Kevin M. Johnson, M.D. Yale University
% Revised 04-Jan-2019

% Run K nearest neighbors model for each outcome group

%Three outcomes were defined: all deaths, coronary artery disease deaths,
%and CHD deaths plus myocardial infarctions. The variable numbering 1
%through 3 generallly refers to these three outcomes.

%Inputs: CCTAtables are generated by the B_threshold_inputs.m function.
%Outputs: scores_KNN1 are the linear discriminant scores
%         X_KNN1 and Y_KNN1 define the ROC curve for all deaths
%         AUC_KNN1 is a 1x3 vector containing the AUCs, followed by the
%         pointwise bootstrap confidence interval upper and lower bounds

%This routine is time consuming. To run much faster, disable bootstrapping. 
%No confidence intervals will be returned in that case.
    bootstrapping='off';%'on' or 'off'
    
% %select parameters for model
    Distance='Cosine'; %'Cosine' or 'Euclidean'
    NumNeighbors=1200;
    DistanceWeight='Equal';
    
%load data
    load input_data/CCTAtable1.mat
    load input_data/CCTAtable2.mat
    load input_data/CCTAtable3.mat

%all deaths
    [response_KNN1,scores_KNN1,X_KNN1,Y_KNN1,T_KNN1,AUC_KNN1] = func_KNN(CCTAtable1,Distance,NumNeighbors,DistanceWeight,bootstrapping);
   
%CHD deaths
    [response_KNN2,scores_KNN2,X_KNN2,Y_KNN2,T_KNN2,AUC_KNN2] = func_KNN(CCTAtable2,Distance,NumNeighbors,DistanceWeight,bootstrapping);
  
%CHD deaths + MI
    [response_KNN3,scores_KNN3,X_KNN3,Y_KNN3,T_KNN3,AUC_KNN3] = func_KNN(CCTAtable3,Distance,NumNeighbors,DistanceWeight,bootstrapping);
     
% Make results table
    NNeighbors_results_table=table(AUC_KNN1',AUC_KNN2',AUC_KNN3');
    NNeighbors_results_table.Properties.VariableNames{'Var1'}='KNN_AUC_alldeaths';
    NNeighbors_results_table.Properties.VariableNames{'Var2'}='KNN_AUC_CHDdeaths';
    NNeighbors_results_table.Properties.VariableNames{'Var3'}='KNN_AUC_CHDdeathsplusMI';
    NNeighbors_results_table.Properties.VariableDescriptions={'AUC followed by CI','AUC followed by CI','AUC followed by CI'};
    NNeighbors_results_table.Properties.UserData.Distance=Distance;
    NNeighbors_results_table.Properties.UserData.NumNeighbors=NumNeighbors;
    NNeighbors_results_table.Properties.UserData.DistanceWeight=DistanceWeight;
    NNeighbors_results_table.Properties.UserData.percentile=parameter.percentile;
    NNeighbors_results_table.Properties.UserData
    disp(NNeighbors_results_table)

% Save
    save('results/NNeighbors_results_table','NNeighbors_results_table')
    writetable(NNeighbors_results_table,'results/NNeighbors_results_table')
    
    
function [response,scores,X_KNN,Y_KNN,T_KNN,AUC_KNN,validationAccuracy] = func_KNN(trainingData,Distance,NumNeighbors,DistanceWeight,bootstrapping)

    %This code was adapted from the MATLAB Classification Learner App code generator output
   
    % Extract predictors and response
        inputTable = trainingData;

    % Split matrices in the input table into vectors
        predictorNames =inputTable.Properties.VariableNames(1:end-1);
        predictors = inputTable(:, predictorNames);
        outcomeName =inputTable.Properties.VariableNames(end);
        response = table2array(inputTable(:, outcomeName));
        
    % Train a classifier
        classificationKNN = fitcknn(...
            predictors, ...
            response, ...
            'Distance', Distance, ...
            'Exponent', [], ...
            'NumNeighbors', NumNeighbors, ...
            'DistanceWeight', DistanceWeight, ...
            'Standardize', true, ...
            'ClassNames', categorical({'0'; '1'}));

    % Create the result struct with predict function
        splitMatricesInTableFcn = @(t) [t(:,setdiff(t.Properties.VariableNames, {'inputs'})), array2table(table2array(t(:,{'inputs'})), 'VariableNames', {'inputs_1', 'inputs_2', 'inputs_3', 'inputs_4', 'inputs_5', 'inputs_6', 'inputs_7', 'inputs_8', 'inputs_9', 'inputs_10', 'inputs_11', 'inputs_12', 'inputs_13', 'inputs_14', 'inputs_15', 'inputs_16', 'inputs_17', 'inputs_18', 'inputs_19', 'inputs_20', 'inputs_21', 'inputs_22', 'inputs_23', 'inputs_24', 'inputs_25', 'inputs_26', 'inputs_27', 'inputs_28', 'inputs_29', 'inputs_30', 'inputs_31', 'inputs_32'})];
        extractPredictorsFromTableFcn = @(t) t(:, predictorNames);
        predictorExtractionFcn = @(x) extractPredictorsFromTableFcn(splitMatricesInTableFcn(x));
        ensemblePredictFcn = @(x) predict(classificationKNN, x);
        trainedClassifier.predictFcn = @(x) ensemblePredictFcn(predictorExtractionFcn(x));

    % Add additional fields to the result struct
        trainedClassifier.RequiredVariables = {'inputs'};
        trainedClassifier.ClassificationEnsemble = classificationKNN;
        trainedClassifier.About = 'This struct is a trained model exported from Classification Learner R2017b.';
        trainedClassifier.HowToPredict = sprintf('To make predictions on a new table, T, use: \n  yfit = c.predictFcn(T) \nreplacing ''c'' with the name of the variable that is this struct, e.g. ''trainedModel''. \n \nThe table, T, must contain the variables returned by: \n  c.RequiredVariables \nVariable formats (e.g. matrix/vector, datatype) must match the original training data. \nAdditional variables are ignored. \n \nFor more information, see <a href="matlab:helpview(fullfile(docroot, ''stats'', ''stats.map''), ''appclassification_exportmodeltoworkspace'')">How to predict using an exported model</a>.');

    % Perform cross-validation
        partitionedModel = crossval(trainedClassifier.ClassificationEnsemble, 'KFold', 10);

    % Compute validation predictions
        [~,validationScores] = kfoldPredict(partitionedModel);
        scores=validationScores(:,2);
     
    % Compute validation accuracy
        validationAccuracy = 1 - kfoldLoss(partitionedModel, 'LossFun', 'ClassifError');

    % ROC curves with bootstrap confidence intervals
        if strcmp(bootstrapping,'on')
            [X_KNN,Y_KNN,T_KNN,AUC_KNN]=perfcurve(response,scores,1,'nboot',1000);
        else
            [X_KNN,Y_KNN,T_KNN,AUC_KNN]=perfcurve(response,scores,1);
        end
    
end
