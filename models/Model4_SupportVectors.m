
% Script for SVM model
% CCTA data analysis
% Created 07-Apr-2018 Kevin M. Johnson, M.D. Yale University
% Revised 04-Jan-2019

% Run linear SVM for each outcome group

%Three outcomes were defined: all deaths, coronary artery disease deaths,
%and CHD deaths plus myocardial infarctions. The variable numbering 1
%through 3 generallly refers to these three outcomes.

%Inputs: CCTAtables are generated by the B_threshold_inputs.m function.
%Outputs: scores_SVM1 are the linear discriminant scores
%         X_SVM1 and Y_SVM1 define the ROC curve for all deaths
%         AUC_SVM1 is a 1x3 vector containing the AUCs, followed by the
%         pointwise bootstrap confidence interval upper and lower bounds

%This routine is time consuming. To run much faster, disable bootstrapping. 
%No confidence intervals will be returned in that case.
    bootstrapping='off';%'on' or 'off'
    
%select parameters for model
    KernelFunction='linear';%linear or polynomial 
    PolynomialOrder=[];%[] or 2

%load data
    load input_data/CCTAtable1.mat
    load input_data/CCTAtable2.mat
    load input_data/CCTAtable3.mat
    
%Temporarily rename variables so we can use same function for all outcomes
%all deaths
    [response_SVM1,scores_SVM1,X_SVM1,Y_SVM1,T_SVM1,AUC_SVM1] = func_SVM(CCTAtable1,KernelFunction,PolynomialOrder,bootstrapping);
   
%CHD deaths
    [response_SVM2,scores_SVM2,X_SVM2,Y_SVM2,T_SVM2,AUC_SVM2] = func_SVM(CCTAtable2,KernelFunction,PolynomialOrder,bootstrapping);
  
%CHD deaths + MI
    [response_SVM3,scores_SVM3,X_SVM3,Y_SVM3,T_SVM3,AUC_SVM3] = func_SVM(CCTAtable3,KernelFunction,PolynomialOrder,bootstrapping);
     
% Make results table
    SVM_results_table=table(AUC_SVM1',AUC_SVM2',AUC_SVM3');
    SVM_results_table.Properties.VariableNames{'Var1'}='SVM_AUC_alldeaths';
    SVM_results_table.Properties.VariableNames{'Var2'}='SVM_AUC_CHDdeaths';
    SVM_results_table.Properties.VariableNames{'Var3'}='SVM_AUC_CHDdeathsplusMI';
    SVM_results_table.Properties.VariableDescriptions={'AUC followed by CI','AUC followed by CI','AUC followed by CI'};
    SVM_results_table.Properties.UserData.KernelFunction=KernelFunction;
    SVM_results_table.Properties.UserData.PolynomialOrder=PolynomialOrder;
    SVM_results_table.Properties.UserData.percentile=parameter.percentile;
    SVM_results_table.Properties.UserData
    disp(SVM_results_table)

% Save
    save('results/SVM_results_table','SVM_results_table')
    writetable(SVM_results_table,'results/SVM_results_table')

function [response,scores,X_SVM,Y_SVM,T_SVM,AUC_SVM,validationAccuracy] = func_SVM(trainingData,KernelFunction,PolynomialOrder,bootstrapping)

    %This code was adapted from the MATLAB Classification Learner App code generator output
   
    % Extract predictors and response
        inputTable = trainingData;

    % Split matrices in the input table into vectors
        predictorNames =inputTable.Properties.VariableNames(1:end-1);
        predictors = inputTable(:, predictorNames);
        outcomeName =inputTable.Properties.VariableNames(end);
        response = table2array(inputTable(:, outcomeName));
        
    % Train a classifier
        classificationSVM = fitcsvm(...
            predictors, ...
            response, ...
            'KernelFunction', KernelFunction, ...
            'PolynomialOrder', PolynomialOrder, ...
            'KernelScale', 'auto', ...
            'BoxConstraint', 1, ...
            'Standardize', true, ...
            'ClassNames', categorical({'0'; '1'}));

    % Create the result struct with predict function
        splitMatricesInTableFcn = @(t) [t(:,setdiff(t.Properties.VariableNames, {'inputs'})), array2table(table2array(t(:,{'inputs'})), 'VariableNames', {'inputs_1', 'inputs_2', 'inputs_3', 'inputs_4', 'inputs_5', 'inputs_6', 'inputs_7', 'inputs_8', 'inputs_9', 'inputs_10', 'inputs_11', 'inputs_12', 'inputs_13', 'inputs_14', 'inputs_15', 'inputs_16', 'inputs_17', 'inputs_18', 'inputs_19', 'inputs_20', 'inputs_21', 'inputs_22', 'inputs_23', 'inputs_24', 'inputs_25', 'inputs_26', 'inputs_27', 'inputs_28', 'inputs_29', 'inputs_30', 'inputs_31', 'inputs_32'})];
        extractPredictorsFromTableFcn = @(t) t(:, predictorNames);
        predictorExtractionFcn = @(x) extractPredictorsFromTableFcn(splitMatricesInTableFcn(x));
        svmPredictFcn = @(x) predict(classificationSVM, x);
        trainedClassifier.predictFcn = @(x) svmPredictFcn(predictorExtractionFcn(x));

    % Add additional fields to the result struct
        trainedClassifier.RequiredVariables = {'inputs'};
        trainedClassifier.ClassificationSVM = classificationSVM;
        trainedClassifier.About = 'This struct is a trained model exported from Classification Learner R2017b.';
        trainedClassifier.HowToPredict = sprintf('To make predictions on a new table, T, use: \n  yfit = c.predictFcn(T) \nreplacing ''c'' with the name of the variable that is this struct, e.g. ''trainedModel''. \n \nThe table, T, must contain the variables returned by: \n  c.RequiredVariables \nVariable formats (e.g. matrix/vector, datatype) must match the original training data. \nAdditional variables are ignored. \n \nFor more information, see <a href="matlab:helpview(fullfile(docroot, ''stats'', ''stats.map''), ''appclassification_exportmodeltoworkspace'')">How to predict using an exported model</a>.');

    % Perform cross-validation
        partitionedModel = crossval(trainedClassifier.ClassificationSVM, 'KFold', 10);

    % Compute validation predictions
        [~,validationScores] = kfoldPredict(partitionedModel);
        scores=validationScores(:,2);
     
    % Compute validation accuracy
        validationAccuracy = 1 - kfoldLoss(partitionedModel, 'LossFun', 'ClassifError');

    % ROC curves with bootstrap confidence intervals
        if strcmp(bootstrapping,'on')
            [X_SVM,Y_SVM,T_SVM,AUC_SVM]=perfcurve(response,scores,1,'nboot',1000);
        else
            [X_SVM,Y_SVM,T_SVM,AUC_SVM]=perfcurve(response,scores,1);
        end
    
end
