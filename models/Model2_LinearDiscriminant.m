
% Script for Linear Discriminant with diagonal covariance
% CCTA data analysis
% Created 07-Apr-2018 Kevin M. Johnson, M.D. Yale University
% Revised 04-Jan-2019

% Run linear discriminant for each outcome group

%Three outcomes were defined: all deaths, coronary artery disease deaths,
%and CHD deaths plus myocardial infarctions. The variable numbering 1
%through 3 generallly refers to these three outcomes.

%Inputs: CCTAtables are generated by the B_feature_weight_thresholding.m function.
%Outputs: scores_LD1 are the linear discriminant scores
%         X_LD1 and Y_LD1 define the ROC curve for all deaths
%         AUC_LD1 is a 1x3 vector containing the AUCs, followed by the
%         pointwise bootstrap confidence interval upper and lower bounds

%This routine is time consuming. To run much faster, disable bootstrapping. 
%No confidence intervals will be returned in that case.
    bootstrapping='off';%'on' or 'off' 

%load data
    load input_data/CCTAtable1.mat
    load input_data/CCTAtable2.mat
    load input_data/CCTAtable3.mat
    
%all deaths
    [response_LD1,scores_LD1,X_LD1,Y_LD1,T_LD1,AUC_LD1] = func_linear_discriminant(CCTAtable1,bootstrapping);
   
%CHD deaths
    [response_LD2,scores_LD2,X_LD2,Y_LD2,T_LD2,AUC_LD2] = func_linear_discriminant(CCTAtable2,bootstrapping);
  
%CHD deaths + MI
    [response_LD3,scores_LD3,X_LD3,Y_LD3,T_LD3,AUC_LD3] = func_linear_discriminant(CCTAtable3,bootstrapping);
     
% Make results table
    LDiscrim_results_table=table(AUC_LD1',AUC_LD2',AUC_LD3');
    LDiscrim_results_table.Properties.VariableNames{'Var1'}='LD_AUC_alldeaths';
    LDiscrim_results_table.Properties.VariableNames{'Var2'}='LD_AUC_CHDdeaths';
    LDiscrim_results_table.Properties.VariableNames{'Var3'}='LD_AUC_CHDdeathsplusMI';
    LDiscrim_results_table.Properties.UserData.DiscrimType='diagLinear';
    LDiscrim_results_table.Properties.UserData.percentile=parameter.percentile;
    LDiscrim_results_table.Properties.UserData
    disp(LDiscrim_results_table)
    
% Save
    save('results/LDiscrim_results_table','LDiscrim_results_table')
    writetable(LDiscrim_results_table,'results/LDiscrim_results_table')
    
    
function [response,scores,X_LD,Y_LD,T_LD,AUC_LD] = func_linear_discriminant(trainingData,bootstrapping)

%This code was adapted from the MATLAB Classification Learner App code generator output

% Extract predictors and response
    inputTable = trainingData;
    
% Split matrices in the input table into vectors
    predictorNames =inputTable.Properties.VariableNames(1:end-1);
    predictors = inputTable(:, predictorNames);
    outcomeName =inputTable.Properties.VariableNames(end);
    response = table2array(inputTable(:, outcomeName));
        
% Train a classifier
    classificationDiscriminant = fitcdiscr(...
        predictors, ...
        response, ...
        'DiscrimType', 'diagLinear', ...
        'FillCoeffs', 'on', ...
        'ClassNames', categorical({'0'; '1'}));

% Create the result struct with predict function
    splitMatricesInTableFcn = @(t) [t(:,setdiff(t.Properties.VariableNames, {'inputs'})), array2table(table2array(t(:,{'inputs'})), 'VariableNames', {'inputs_1', 'inputs_2', 'inputs_3', 'inputs_4', 'inputs_5', 'inputs_6', 'inputs_7', 'inputs_8', 'inputs_9', 'inputs_10', 'inputs_11', 'inputs_12', 'inputs_13', 'inputs_14', 'inputs_15', 'inputs_16', 'inputs_17', 'inputs_18', 'inputs_19', 'inputs_20', 'inputs_21', 'inputs_22', 'inputs_23', 'inputs_24', 'inputs_25', 'inputs_26', 'inputs_27', 'inputs_28', 'inputs_29', 'inputs_30', 'inputs_31', 'inputs_32'})];
    extractPredictorsFromTableFcn = @(t) t(:, predictorNames);
    predictorExtractionFcn = @(x) extractPredictorsFromTableFcn(splitMatricesInTableFcn(x));
    discriminantPredictFcn = @(x) predict(classificationDiscriminant, x);
    trainedClassifier.predictFcn = @(x) discriminantPredictFcn(predictorExtractionFcn(x));

% Add additional fields to the result struct
    trainedClassifier.ClassificationDiscriminant = classificationDiscriminant;

% Perform cross-validation
    partitionedModel = crossval(trainedClassifier.ClassificationDiscriminant, 'KFold', 10);

% Compute validation predictions
    [~,validationscores] = kfoldPredict(partitionedModel);%first output is validation predictions
    scores=validationscores(:,2);
        
% ROC curves
    if strcmp(bootstrapping,'on')
        [X_LD,Y_LD,T_LD,AUC_LD]=perfcurve(response,scores,1,'nboot',1000);
    else
        [X_LD,Y_LD,T_LD,AUC_LD]=perfcurve(response,scores,1);
    end

end
